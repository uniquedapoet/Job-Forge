{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume.md\", \"r\", encoding=\"utf-8\") as file:\n",
    "    resume = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def clean_text(raw_text):\n",
    "    set_of_stopwords = set(stopwords.words(\"english\") + list(string.punctuation))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Convert text to lowercase and tokenize into words\n",
    "    tokens = word_tokenize(raw_text.lower())\n",
    "    # Remove stopwords and punctuation\n",
    "    tokens = [token for token in tokens if token not in set_of_stopwords]\n",
    "    # Lemmatize the remaining words\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Join the tokens back into a single string\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "resume_content = \"\"\"\n",
    "Abin Varghese\n",
    "LinkedIn • Portfolio Website • GitHub\n",
    "abinvarghese90@gmail.com • Lincoln, UK, LN2 2LG • +447888704879\n",
    "\n",
    "Summary\n",
    "ML Research Engineer in Computer Vision at FruitCast with over 2.4 years of commercial experience, specialising in Natural Language Processing (NLP), Visual Odometry, and SLAM. Proficient in Python and skilled in deploying classical and deep learning applications, with expertise in LSTMs, Transformers, and open-source LLMs like GPT4All. Implemented Federated Machine Learning on clients' IID datasets, driving significant business growth, including raising revenue by a CAGR of 55% in an EdTech startup. Strong track record of leveraging advanced techniques to deliver impactful solutions.\n",
    "\n",
    "Experience\n",
    "\n",
    "FRUITCAST\t             \t\t\t           \t            \t\t                                                                                  Lincoln, United Kingdom\n",
    "Machine Learning Research Engineer (Computer Vision)\t\t\t\t                                                                 03/2024 – Present\n",
    "Research, develop and implement SOTA Visual Odometry and SLAM algorithms for the application in polytunnels.\n",
    "Responsible for tasks including pattern recognition, and application of robotics within the company in liaison with the data engineer and computer vision expert using Visual Odometry and SLAM.\n",
    "Developed and implemented computer vision algorithms, managing large datasets, and working closely in cross-functional teams for data science, mechanical design, sensors, firmware, and software engineering.\n",
    "\n",
    "INFOSYS LTD.\t\t\t\t\t\t           \t            \t\t                                                                       Mysore, India\n",
    "Data Scientist\t\t\t \t\t\t\t\t\t                                                               12/2021 – 12/2022\n",
    "Engineered team leadership: Orchestrated development of an enterprise solution utilising the Attention model to autonomously extract and categorise skills from resumes, leading to substantial cost savings in HR operations at Bangalore and Mysore DC.\n",
    "Contributed to ML projects: Enabled BEF's global impact, attracted external clients like GlobalFoundries, boosting profits in 2021-2022.\n",
    "Created courses: Trained 5000+ employees in ML, NLP, and stats, indirectly increasing revenue.\n",
    "Awarded best author: GPT-3 course in Q2 2022, live to 250,000+ internal employees and external vendors.\n",
    "\n",
    "CORIZO\t\t\t\t\t\t\t           \t            \t\t                                                    Bangalore, India\n",
    "Leader for Data Science and Machine Learning\t\t\t\t                                                                                02/2022 – Present\n",
    "Achieved 55% revenue increase: Led 1000+ students in data science and machine learning, driving growth.\n",
    "Headed highest-revenue department: Developed impactful lessons and projects.\n",
    "\n",
    "BLOOMTECH\t\t\t\t\t\t           \t            \t\t                                                                   California, USA\n",
    "Subject Matter Expert for Data Science\t\t\t\t                                                                                              04/2022 – 06/2022\n",
    "Initiated technical projects: Enhanced data-driven capabilities and delivered projects for their clients.\n",
    "\n",
    "Education\n",
    "Kingston University \t\t\t\t\t\t\t                                                                   London, United Kingdom\n",
    "MSc, Data Science - Distinction\t\t\t\t                                                                                                                        2023 - 2024\n",
    "Dissertation - Bridging the Gap: Exploring Privacy-Enhancing Technologies and Facilitating Collaboration between Academia and Industry through Federated Learning, and 'Privacy-as-Code' System Development.\n",
    "\n",
    "SRM Institute of Science and Technology\t\t\t\t\t   \t \t                                                       Chennai, India\n",
    "B.Tech, Computer Science and Engineering - First Class with Distinction                                                                                                            2016 – 2020\n",
    "\n",
    "Projects\n",
    "Applied Privacy Lite → Used Transformers to redact PII from text and implemented Federated Learning on an IID Dataset.\n",
    "Explain Paper → Used GPT4All Open-Source LLM to convert research papers into plain English. Working on deploying it now.\n",
    "US Crime Statistics → Analyzed the US crime statistics in the state of Maryland and deployed it for visualisations.\n",
    "SUPPORT2 → Performed extensive EDA and Feature Engineering on the SUPPORT2 health dataset and deployed it.\n",
    "GAN implementation→ The goal is to grasp GAN principles for generating new digit images.\n",
    "A-B Testing ML Model Performance → This project compares BERT and DistilBERT models for QA systems via A/B testing.\n",
    "Real Estate Price Prediction with NLP → Created a real estate price prediction model, hosted on Heroku using FastAPI.\n",
    "Credit Card Fraud Detection → Created and deployed using Streamlit 4 robust deep-learning fraud detection models.\n",
    "Flight Ticket Price Predictor → Developed a flight ticket price prediction model using multiple features with over 99% accuracy.\n",
    "Fake News Classifier → Built the LSTM model from scratch to classify fake and legitimate news.\n",
    "Hackathon: Cybertrendz → Special mention for tech-driven privacy solution with policy-to-checklist conversion.\n",
    "Single Pong Player Game → Single-player Pong game with paddle control, score tracking, and specified score limit.\n",
    "Conway’s Game of Life → Python implementation of Conway's Game of Life, simulating life-like patterns on a grid.\n",
    "\n",
    "Skills\n",
    "Expert: Python 3.X, MySQL, SQL, Classical and Deep Machine Learning, Data Science, NLP, Keras, TensorFlow, PyTorch, Scikit-Learn, Federated Learning.\n",
    "Proficient: Azure, Prompt Engineering, Django, Java, CNN, Linux, Tableau, AB Testing.\n",
    "\n",
    "Leadership, Volunteering and Certifications\n",
    "Microsoft Learn Student Ambassador → Community leader representing Microsoft. Conducted workshops on generative AI.\n",
    "Applied Privacy Podcast → Hosts Applied Privacy podcast with industry leaders (CEOs, CPOs etc.) on privacy from various perspectives.\n",
    "Ukraine Global Taskforce → Data curator aiding Ukraine war logistics, creating live bombing alert heatmap.\n",
    "Licenses and Certifications → Please click on this hyperlink to view all the certifications.\n",
    "References are available upon request.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_skills(resume_content):\n",
    "\n",
    "    skills_pattern = re.compile(r'Skills\\s*[:\\n]', re.IGNORECASE)\n",
    "    skills_match = skills_pattern.search(resume_content)\n",
    "\n",
    "    if skills_match:\n",
    "        skills_start = skills_match.end()\n",
    "        skills_end = resume_content.find('\\n\\n', skills_start)\n",
    "        skills_section = resume_content[skills_start:skills_end].strip()\n",
    "        skills_lines = skills_section.split('\\n')\n",
    "\n",
    "        extracted_skills = []\n",
    "        for line in skills_lines:\n",
    "            line_skills = re.split(r'[:,-]', line)\n",
    "            extracted_skills.extend([skill.strip() for skill in line_skills if skill.strip()])\n",
    "\n",
    "        return list(set(extracted_skills))\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "extract_skills(resume)\n",
    "\n",
    "# def extract_experience(resume_text):\n",
    "#     \"\"\"\n",
    "#     Extracts the work experience section from the resume content.\n",
    "\n",
    "#     :return: Experience section as a string\n",
    "#     \"\"\"\n",
    "\n",
    "#     RESUME_SECTIONS = [\n",
    "#         \"Contact Information\", \"Objective\", \"Summary\", \"Education\", \"Experience\", \n",
    "#         \"Skills\", \"Projects\", \"Certifications\", \"Licenses\", \"Awards\", \"Honors\", \n",
    "#         \"Publications\", \"References\", \"Technical Skills\", \"Computer Skills\", \n",
    "#         \"Programming Languages\", \"Software Skills\", \"Soft Skills\", \"Language Skills\", \n",
    "#         \"Professional Skills\", \"Transferable Skills\", \"Work Experience\", \n",
    "#         \"Professional Experience\", \"Employment History\", \"Internship Experience\", \n",
    "#         \"Volunteer Experience\", \"Leadership Experience\", \"Research Experience\", \n",
    "#         \"Teaching Experience\",\n",
    "#     ]\n",
    "\n",
    "#     experience_start = resume_text.find(\"Experience\")\n",
    "#     if experience_start == -1:\n",
    "#         return \"\"\n",
    "\n",
    "#     experience_end = len(resume_text)\n",
    "#     for section in RESUME_SECTIONS:\n",
    "#         if section != \"Experience\":\n",
    "#             section_start = resume_text.find(section, experience_start)\n",
    "#             if section_start != -1:\n",
    "#                 experience_end = min(experience_end, section_start)\n",
    "\n",
    "#     experience_section = resume_text[experience_start:experience_end].strip()\n",
    "#     return experience_section\n",
    "\n",
    "# print(extract_experience(cleaned_resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN',\n",
       " 'Tableau',\n",
       " 'Proficient',\n",
       " 'AB Testing.',\n",
       " 'Learn',\n",
       " 'Linux',\n",
       " 'Azure',\n",
       " 'MySQL',\n",
       " 'Data Science',\n",
       " 'Django',\n",
       " 'Java',\n",
       " 'Python 3.X',\n",
       " 'PyTorch',\n",
       " 'Prompt Engineering',\n",
       " 'Keras',\n",
       " 'TensorFlow',\n",
       " 'Classical and Deep Machine Learning',\n",
       " 'Scikit',\n",
       " 'SQL',\n",
       " 'NLP',\n",
       " 'Expert',\n",
       " 'Federated Learning.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_skills(resume_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(cleaned_resume, cleaned_jd):\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    sentences = [cleaned_resume, cleaned_jd]\n",
    "    embeddings1 = model.encode(sentences[0])\n",
    "    embeddings2 = model.encode(sentences[1])\n",
    "    \n",
    "    similarity_score = model.similarity(embeddings1, embeddings2)\n",
    "\n",
    "    return similarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p j g ( )\n",
      "https://github.com/jacksongiemza boulder, co\n",
      "\n",
      "enthusiastic information science student with hands-on experience as a data scientist,\n",
      "equipped with technical and analytical skills to derive data-driven decisions. passionate\n",
      "about harnessing data to solve complex meaningful problems in a vibrant, innovative setting.\n",
      "\n",
      "education\n",
      "university of colorado, boulder, co | expected graduation may 2025 bachelor of science, information science | minor: philosophy\n",
      "relevant courses:                               applications & programs:\n",
      "data visualization, statistics, python for info sci 1&2       python (pandas, numpy, matplotlib, altair), excel,\n",
      "r for data science, logic, quantitative reason.            openai api, selenium, git, r, sql, excel, tableau,\n",
      "tkinter, power platforms.\n",
      "\n",
      "experience\n",
      "risk technology analyst | rj o’brien associates        may 2024 - aug. 2024, chicago, il\n",
      "i was invited to return to rjo’s risk team following my internship with them in 2022. drawing on the\n",
      "skills i developed through prior internships and academic work, i successfully led key projects from\n",
      "concept to completion and contributed to several other high-impact initiatives.\n",
      "developed a python-based solution to automate financial audit requests, reducing work for\n",
      "credit analysts by dynamically generating and scheduling personalized emails.\n",
      "led the project from concept to deployment, including training future maintainers and creating\n",
      "a power bi dashboard for monitoring requests and manually sending emails ad hoc.\n",
      "identified the need for and developed a python gui for generating customized anonymous test\n",
      "data for users of all technical expertise.\n",
      "served as an ambassador for new ai tools by interviewing coworkers to identify pain points in\n",
      "ai adoption and conducting demos to facilitate user adoption and streamline workflows.\n",
      "\n",
      "data science intern | cloudquant may 2023 - aug. 2023, chicago, il\n",
      "over my productive summer at cloudquant, i successfully executed 4 major projects\n",
      "and efficiently managed numerous smaller tasks, with strong commitment to driving\n",
      "significant results.\n",
      "expanded the data catalog by 8000+ datasets through seamless integration\n",
      "of various data apis.\n",
      "developed dynamic web scrapers using selenium for building datasets.\n",
      "strategically utilized the new openai api to automate data entry and cleaning\n",
      "processes, significantly enhancing efficiency while reducing manual workload.\n",
      "drove insights through analysis and data visualization\n",
      "\n",
      "summer intern | rj o’brien associates                may 2022 - aug. 2022, chicago, il\n",
      "throughout my summer at rjo, the oldest and largest independent futures brokerage\n",
      "firm in the us, i worked on various projects and tasks for the credit and risk teams.\n",
      "engineered automated risk reports for quarterly and daily distribution.\n",
      "streamlined customer financial information retrieval by designing a centralized interface with\n",
      "microsoft powerapps for the credit team.\n",
      "designed a comprehensive financial analysis dashboard for evaluating vendor viability\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_markdown(text):\n",
    "    \"\"\"Removes advanced Markdown syntax while preserving readable text.\"\"\"\n",
    "    \n",
    "    # Remove headers (e.g., ###, ##, #)\n",
    "    text = re.sub(r'#{1,6}\\s*', '', text)  \n",
    "\n",
    "    # Remove bold (**text**) and italic (*text* or _text_)\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)  # Bold\n",
    "    text = re.sub(r'\\*(.*?)\\*', r'\\1', text)      # Italic\n",
    "    text = re.sub(r'_(.*?)_', r'\\1', text)        # Italic with underscore\n",
    "    \n",
    "    # Remove inline code (`code`)\n",
    "    text = re.sub(r'`(.*?)`', r'\\1', text)\n",
    "\n",
    "    # Remove links but keep the anchor text: [text](url)\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', text)\n",
    "\n",
    "    # Remove horizontal rules (---, ***, ___)\n",
    "    text = re.sub(r'(\\n[-*_]{3,}\\n)', '\\n', text)\n",
    "\n",
    "    # Remove list markers (-, *, +) and extra spaces\n",
    "    text = re.sub(r'^\\s*[-*+] ', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove extra spaces caused by formatting\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text).strip()\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "resume_cleaned = clean_markdown(resume)\n",
    "\n",
    "print(resume_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['data-driven decisions', 'derive data-driven', 'data', 'science', 'information science', 'science student', 'enthusiastic information', 'data science', 'data scientist', 'hands-on experience', 'analytical skills', 'information', 'developed', 'boulder', 'risk', 'aug', 'chicago', 'projects', 'python', 'excel', 'scientist', 'equipped', 'decisions', 'data visualization', 'summer', 'credit', 'enthusiastic', 'student', 'hands-on', 'analytical', 'derive', 'data-driven', 'financial', 'experience', 'o’brien associates', 'science intern', 'openai api', 'innovative setting', 'skills', 'concept', 'technical', 'solve complex', 'complex meaningful', 'meaningful problems', 'api', 'financial information', 'power', 'o’brien', 'associates', 'harnessing data', 'team', 'work', 'visualization', 'openai', 'successfully', 'experience risk', 'led', 'intern', 'requests', 'emails', 'generating', 'automate', 'selenium', 'adoption', 'dashboard', 'rjo', 'reducing', 'cloudquant', 'datasets', 'tasks', 'analysis', 'data apis', 'information retrieval', 'quantitative reason', 'automate data', 'risk team', 'risk teams', 'education university', 'expected graduation', 'philosophy relevant', 'info sci', 'passionate', 'vibrant', 'innovative', 'setting', 'credit analysts', 'harnessing', 'solve', 'complex', 'meaningful', 'problems', 'power platforms', 'credit team', 'visualization summer', 'summer intern', 'key projects', 'project', 'risk technology', 'successfully led', 'minor', 'applications', 'programs', 'statistics', 'pandas', 'numpy', 'matplotlib', 'altair', 'logic', 'test data', 'major projects', 'education', 'colorado', 'expected', 'bachelor', 'philosophy', 'sci', 'quantitative', 'reason', 'data catalog', 'reducing work', 'data entry', 'automate financial', 'technology analyst', 'git', 'sql', 'tableau', 'tkinter', 'apis', 'developed dynamic', 'user adoption', 'analyst', 'internship', 'internships', 'analysts', 'university', 'graduation', 'relevant', 'info', 'python gui', 'teams', 'technical expertise', 'platforms', 'prior internships', 'users', 'user', 'automated risk', 'risk reports', 'future', 'futures', 'academic work', 'financial analysis', 'led key', 'technology', 'analysis dashboard', 'drawing', 'initiatives', 'invited', 'return', 'audit requests', 'personalized emails', 'successfully executed', 'deployment', 'including', 'hoc', 'prior', 'academic', 'key', 'completion', 'contributed', 'high-impact', 'dynamically generating', 'identified', 'expertise', 'monitoring requests', 'sending emails', 'python-based', 'solution', 'audit', 'dynamically', 'scheduling', 'personalized', 'productive summer', 'served', 'workflows', 'financial audit', 'training', 'maintainers', 'creating', 'monitoring', 'manually', 'sending', 'executed', 'major', 'results', 'expanded', 'gui', 'customized', 'anonymous', 'test', 'generating customized']\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/LIAAD/yake\n",
    "\n",
    "import yake\n",
    "\n",
    "def yake_extract_keywords(text, num_keywords=10):\n",
    "    \"\"\"Extracts top keywords using YAKE.\"\"\"\n",
    "    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=2, dedupLim=1, top=200)\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    return [kw[0] for kw in keywords]  # Return only the keyword text\n",
    "\n",
    "\n",
    "keywords = yake_extract_keywords(resume_cleaned)\n",
    "\n",
    "print(len(keywords))\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "['developed dynamic web scrapers using selenium', 'largest independent futures brokerage firm', 'expected graduation may 2025 bachelor', 'manually sending emails ad hoc', 'streamlined customer financial information retrieval', 'successfully executed 4 major projects', 'efficiently managed numerous smaller tasks', '’ brien associates may 2024', 'generating customized anonymous test data', '’ brien associates may 2022', 'co enthusiastic information science student', 'solve complex meaningful problems', 'including training future maintainers', 'engineered automated risk reports', 'automate financial audit requests', 'successfully led key projects', 'comprehensive financial analysis dashboard', 'experience risk technology analyst', 'data visualization summer intern', 'scheduling personalized emails', 'automate data entry', 'significantly enhancing efficiency', 'power bi dashboard', 'philosophy relevant courses', 'p j g', 'info sci 1', 'identify pain points', 'https :// github', 'evaluating vendor viability', 'driving significant results', 'data science intern', 'risk team following', 'reducing manual workload', 'new ai tools', 'facilitate user adoption', 'cloudquant may 2023', 'various data apis', 'new openai api', 'altair ), excel', 'information science', 'various projects', 'data visualization', 'rjo ’', 'dynamically generating', 'data science', 'risk teams', 'openai api', 'monitoring requests', 'ai adoption', 'harnessing data', 'derive data', 'data scientist', 'data catalog', 'reducing work', 'power platforms', 'productive summer', 'credit team', 'strong commitment', 'streamline workflows', 'strategically utilized', 'seamless integration', 'quantitative reason', 'prior internships', 'microsoft powerapps', 'interviewing coworkers', 'innovative setting', 'impact initiatives', 'education university', 'drove insights', 'driven decisions', 'daily distribution', 'conducting demos', 'cleaning processes', 'centralized interface', 'based solution', 'academic work', 'credit analysts', 'technical expertise', 'selenium', 'python gui', 'jacksongiemza boulder', 'building datasets', 'analytical skills', '2 python', 'il throughout', 'tasks', 'co', '2024', 'science', 'led', 'experience', 'analysis', 'summer', '2022', '2022', 'developed', 'developed', 'developed', 'excel', 'cloudquant', '2023', 'credit', 'technical', 'skills', 'rjo', 'python', 'python', 'datasets', 'boulder', 'il', 'il', 'worked', 'vibrant', 'users', 'us', 'tkinter', 'tableau', 'statistics', 'sql', 'several', 'served', 'rj', 'rj', 'return', 'r', 'r', 'quarterly', 'project', 'programs', 'passionate', 'pandas', 'oldest', 'numpy', 'need', 'minor', 'matplotlib', 'logic', 'invited', 'internship', 'identified', 'high', 'hands', 'git', 'expanded', 'equipped', 'drawing', 'designing', 'designed', 'deployment', 'creating', 'contributed', 'concept', 'concept', 'completion', 'com', 'colorado', 'chicago', 'chicago', 'chicago', 'aug', 'aug', 'aug', 'applications', 'ambassador', '8000']\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.org/project/rake-nltk/\n",
    "\n",
    "from rake_nltk import Rake\n",
    "\n",
    "def nltk_rake(text):\n",
    "    rake_nltk_var = Rake()\n",
    "\n",
    "    rake_nltk_var.extract_keywords_from_text(text)\n",
    "    keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "\n",
    "    return keyword_extracted\n",
    "\n",
    "nltk_keywords = nltk_rake(resume_cleaned)\n",
    "\n",
    "print(len(nltk_keywords))\n",
    "print(nltk_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jacks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
