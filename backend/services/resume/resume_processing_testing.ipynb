{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume.md\", \"r\", encoding=\"utf-8\") as file:\n",
    "    resume = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_markdown(text):\n",
    "    \"\"\"Removes advanced Markdown syntax while preserving readable text.\"\"\"\n",
    "    \n",
    "    # Remove headers (e.g., ###, ##, #)\n",
    "    text = re.sub(r'#{1,6}\\s*', '', text)  \n",
    "\n",
    "    # Remove bold (**text**) and italic (*text* or _text_)\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)  # Bold\n",
    "    text = re.sub(r'\\*(.*?)\\*', r'\\1', text)      # Italic\n",
    "    text = re.sub(r'_(.*?)_', r'\\1', text)        # Italic with underscore\n",
    "    \n",
    "    # Remove inline code (`code`)\n",
    "    text = re.sub(r'`(.*?)`', r'\\1', text)\n",
    "\n",
    "    # Remove links but keep the anchor text: [text](url)\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', text)\n",
    "\n",
    "    # Remove horizontal rules (---, ***, ___)\n",
    "    text = re.sub(r'(\\n[-*_]{3,}\\n)', '\\n', text)\n",
    "\n",
    "    # Remove list markers (-, *, +) and extra spaces\n",
    "    text = re.sub(r'^\\s*[-*+] ', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove extra spaces caused by formatting\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text).strip()\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "resume_cleaned = clean_markdown(resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['data-driven decisions', 'derive data-driven', 'data', 'science', 'information science', 'science student', 'enthusiastic information', 'data science', 'data scientist', 'hands-on experience', 'analytical skills', 'information', 'developed', 'boulder', 'risk', 'aug', 'chicago', 'projects', 'python', 'excel', 'scientist', 'equipped', 'decisions', 'data visualization', 'summer', 'credit', 'enthusiastic', 'student', 'hands-on', 'analytical', 'derive', 'data-driven', 'financial', 'experience', 'o’brien associates', 'science intern', 'openai api', 'innovative setting', 'skills', 'concept', 'technical', 'solve complex', 'complex meaningful', 'meaningful problems', 'api', 'financial information', 'power', 'o’brien', 'associates', 'harnessing data', 'team', 'work', 'visualization', 'openai', 'successfully', 'experience risk', 'led', 'intern', 'requests', 'emails', 'generating', 'automate', 'selenium', 'adoption', 'dashboard', 'rjo', 'reducing', 'cloudquant', 'datasets', 'tasks', 'analysis', 'data apis', 'information retrieval', 'quantitative reason', 'automate data', 'risk team', 'risk teams', 'education university', 'expected graduation', 'philosophy relevant', 'info sci', 'passionate', 'vibrant', 'innovative', 'setting', 'credit analysts', 'harnessing', 'solve', 'complex', 'meaningful', 'problems', 'power platforms', 'credit team', 'visualization summer', 'summer intern', 'key projects', 'project', 'risk technology', 'successfully led', 'minor', 'applications', 'programs', 'statistics', 'pandas', 'numpy', 'matplotlib', 'altair', 'logic', 'test data', 'major projects', 'education', 'colorado', 'expected', 'bachelor', 'philosophy', 'sci', 'quantitative', 'reason', 'data catalog', 'reducing work', 'data entry', 'automate financial', 'technology analyst', 'git', 'sql', 'tableau', 'tkinter', 'apis', 'developed dynamic', 'user adoption', 'analyst', 'internship', 'internships', 'analysts', 'university', 'graduation', 'relevant', 'info', 'python gui', 'teams', 'technical expertise', 'platforms', 'prior internships', 'users', 'user', 'automated risk', 'risk reports', 'future', 'futures', 'academic work', 'financial analysis', 'led key', 'technology', 'analysis dashboard', 'drawing', 'initiatives', 'invited', 'return', 'audit requests', 'personalized emails', 'successfully executed', 'deployment', 'including', 'hoc', 'prior', 'academic', 'key', 'completion', 'contributed', 'high-impact', 'dynamically generating', 'identified', 'expertise', 'monitoring requests', 'sending emails', 'python-based', 'solution', 'audit', 'dynamically', 'scheduling', 'personalized', 'productive summer', 'served', 'workflows', 'financial audit', 'training', 'maintainers', 'creating', 'monitoring', 'manually', 'sending', 'executed', 'major', 'results', 'expanded', 'gui', 'customized', 'anonymous', 'test', 'generating customized']\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/LIAAD/yake\n",
    "\n",
    "import yake\n",
    "\n",
    "def yake_extract_keywords(text, num_keywords=10):\n",
    "    \"\"\"Extracts top keywords using YAKE.\"\"\"\n",
    "    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=2, dedupLim=1, top=200)\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    return [kw[0] for kw in keywords]  # Return only the keyword text\n",
    "\n",
    "\n",
    "keywords = yake_extract_keywords(resume_cleaned)\n",
    "\n",
    "print(len(keywords))\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "['developed dynamic web scrapers using selenium', 'largest independent futures brokerage firm', 'expected graduation may 2025 bachelor', 'manually sending emails ad hoc', 'streamlined customer financial information retrieval', 'successfully executed 4 major projects', 'efficiently managed numerous smaller tasks', '’ brien associates may 2024', 'generating customized anonymous test data', '’ brien associates may 2022', 'co enthusiastic information science student', 'solve complex meaningful problems', 'including training future maintainers', 'engineered automated risk reports', 'automate financial audit requests', 'successfully led key projects', 'comprehensive financial analysis dashboard', 'experience risk technology analyst', 'data visualization summer intern', 'scheduling personalized emails', 'automate data entry', 'significantly enhancing efficiency', 'power bi dashboard', 'philosophy relevant courses', 'p j g', 'info sci 1', 'identify pain points', 'https :// github', 'evaluating vendor viability', 'driving significant results', 'data science intern', 'risk team following', 'reducing manual workload', 'new ai tools', 'facilitate user adoption', 'cloudquant may 2023', 'various data apis', 'new openai api', 'altair ), excel', 'information science', 'various projects', 'data visualization', 'rjo ’', 'dynamically generating', 'data science', 'risk teams', 'openai api', 'monitoring requests', 'ai adoption', 'harnessing data', 'derive data', 'data scientist', 'data catalog', 'reducing work', 'power platforms', 'productive summer', 'credit team', 'strong commitment', 'streamline workflows', 'strategically utilized', 'seamless integration', 'quantitative reason', 'prior internships', 'microsoft powerapps', 'interviewing coworkers', 'innovative setting', 'impact initiatives', 'education university', 'drove insights', 'driven decisions', 'daily distribution', 'conducting demos', 'cleaning processes', 'centralized interface', 'based solution', 'academic work', 'credit analysts', 'technical expertise', 'selenium', 'python gui', 'jacksongiemza boulder', 'building datasets', 'analytical skills', '2 python', 'il throughout', 'tasks', 'co', '2024', 'science', 'led', 'experience', 'analysis', 'summer', '2022', '2022', 'developed', 'developed', 'developed', 'excel', 'cloudquant', '2023', 'credit', 'technical', 'skills', 'rjo', 'python', 'python', 'datasets', 'boulder', 'il', 'il', 'worked', 'vibrant', 'users', 'us', 'tkinter', 'tableau', 'statistics', 'sql', 'several', 'served', 'rj', 'rj', 'return', 'r', 'r', 'quarterly', 'project', 'programs', 'passionate', 'pandas', 'oldest', 'numpy', 'need', 'minor', 'matplotlib', 'logic', 'invited', 'internship', 'identified', 'high', 'hands', 'git', 'expanded', 'equipped', 'drawing', 'designing', 'designed', 'deployment', 'creating', 'contributed', 'concept', 'concept', 'completion', 'com', 'colorado', 'chicago', 'chicago', 'chicago', 'aug', 'aug', 'aug', 'applications', 'ambassador', '8000']\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.org/project/rake-nltk/\n",
    "\n",
    "from rake_nltk import Rake\n",
    "\n",
    "def nltk_rake(text):\n",
    "    rake_nltk_var = Rake()\n",
    "\n",
    "    rake_nltk_var.extract_keywords_from_text(text)\n",
    "    keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "\n",
    "    return keyword_extracted\n",
    "\n",
    "nltk_keywords = nltk_rake(resume_cleaned)\n",
    "\n",
    "print(len(nltk_keywords))\n",
    "print(nltk_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jacks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
