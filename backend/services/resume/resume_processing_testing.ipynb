{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sbert.net/\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def clean_text(raw_text):\n",
    "    set_of_stopwords = set(stopwords.words(\"english\") + list(string.punctuation))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Convert text to lowercase and tokenize into words\n",
    "    tokens = word_tokenize(raw_text.lower())\n",
    "    # Remove stopwords and punctuation\n",
    "    tokens = [token for token in tokens if token not in set_of_stopwords]\n",
    "    # Lemmatize the remaining words\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Join the tokens back into a single string\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "def clean_resume(resume_content):\n",
    "    skills_pattern = re.compile(r'Skills\\s*[:\\n]', re.IGNORECASE)\n",
    "    skills_match = skills_pattern.search(resume_content)\n",
    "\n",
    "    if skills_match:\n",
    "        skills_start = skills_match.end()\n",
    "        skills_end = resume_content.find('\\n\\n', skills_start)\n",
    "        skills_section = resume_content[skills_start:skills_end].strip()\n",
    "        skills_lines = skills_section.split('\\n')\n",
    "\n",
    "        extracted_skills = []\n",
    "        for line in skills_lines:\n",
    "            line_skills = re.split(r'[:,-]', line)\n",
    "            extracted_skills.extend([skill.strip() for skill in line_skills if skill.strip()])\n",
    "\n",
    "        skills = list(set(extracted_skills))\n",
    "    else:\n",
    "        skills = []\n",
    "\n",
    "    skills = \", \".join(skills)\n",
    "\n",
    "    RESUME_SECTIONS = [\n",
    "        \"Contact Information\", \"Objective\", \"Summary\", \"Education\", \"Experience\", \n",
    "        \"Skills\", \"Projects\", \"Certifications\", \"Licenses\", \"Awards\", \"Honors\", \n",
    "        \"Publications\", \"References\", \"Technical Skills\", \"Computer Skills\", \n",
    "        \"Programming Languages\", \"Software Skills\", \"Soft Skills\", \"Language Skills\", \n",
    "        \"Professional Skills\", \"Transferable Skills\", \"Work Experience\", \n",
    "        \"Professional Experience\", \"Employment History\", \"Internship Experience\", \n",
    "        \"Volunteer Experience\", \"Leadership Experience\", \"Research Experience\", \n",
    "        \"Teaching Experience\",\n",
    "    ]\n",
    "\n",
    "    experience_start = resume_content.find(\"Experience\")\n",
    "    if experience_start == -1:\n",
    "        return \"\"\n",
    "\n",
    "    experience_end = len(resume_content)\n",
    "    for section in RESUME_SECTIONS:\n",
    "        if section != \"Experience\":\n",
    "            section_start = resume_content.find(section, experience_start)\n",
    "            if section_start != -1:\n",
    "                experience_end = min(experience_end, section_start)\n",
    "\n",
    "    experience_section = resume_content[experience_start:experience_end].strip()\n",
    "\n",
    "    cleaned_experience = clean_text(experience_section)\n",
    "\n",
    "    cleaned_skills = clean_text(skills)\n",
    "\n",
    "\n",
    "    return cleaned_experience + cleaned_skills\n",
    "\n",
    "def compute_similarity(cleaned_resume, cleaned_jd):\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    sentences = [cleaned_resume, cleaned_jd]\n",
    "    embeddings1 = model.encode(sentences[0])\n",
    "    embeddings2 = model.encode(sentences[1])\n",
    "    \n",
    "    similarity_score = model.similarity(embeddings1, embeddings2)\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_content = \"\"\"\n",
    "    Jackson Giemza\n",
    "    Boulder, CO | (708)-340-8105 | jackson.giemza@gmail.com | github.com/JacksonGiemza \n",
    "\n",
    "    Enthusiastic information science student with hands-on experience as a data scientist, equipped with\n",
    "    technical and analytical skills to derive data-driven decisions. Passionate about harnessing data to\n",
    "    solve complex, meaningful problems in a vibrant, innovative setting.\n",
    "    Education\n",
    "    \n",
    "    University of Colorado, Boulder, CO | Expected Graduation Dec 2025\n",
    "    Bachelor of Science, Information Science | Minor, Philosophy \n",
    "    Relevant Courses: Data Visualization, Statistics, Python for Info Sci 1&2, Linear Algebra, R for\n",
    "    Data Science, Logic, Quantitative Reasoning, Physics 1&2, Calculus, Economics, UI/UX Design\n",
    "\n",
    "    Experience\n",
    "    Risk Technology Analyst | RJ O’Brien & Associates\n",
    "    May 2024 - Aug. 2024, Chicago, IL\n",
    "    Developed a Python-based solution to automate financial audit requests, reducing work for\n",
    "    analysts by dynamically generating and scheduling 15+ personalized emails bi-weekly\n",
    "    Led the project from concept to deployment, including training future maintainers and creating\n",
    "    a Power BI dashboard for monitoring requests and manually sending custom emails ad hoc\n",
    "    Identified the need for and developed a Python GUI for generating customized anonymous test\n",
    "    data for users of all technical expertise\n",
    "    Served as an ambassador for new AI tools by interviewing coworkers to identify pain points in\n",
    "    AI adoption and conducting 10+ one-on-one demos teaching how to leverage gen. AI \n",
    "\n",
    "    Data Science Intern | CloudQuant\n",
    "    May 2023 - Aug. 2023, Chicago, IL\n",
    "    Expanded the data catalog by 8000+ datasets through seamless integration of various data APIs\n",
    "    and dynamic web scrapers\n",
    "    Strategically utilized the new OpenAI API to automate data entry and cleaning processes,\n",
    "    significantly enhancing efficiency while reducing manual workload\n",
    "    Drove insights through analysis and data visualization\n",
    "\n",
    "    Summer Intern | RJ O’Brien & Associates\n",
    "    May 2022 - Aug. 2022, Chicago, IL\n",
    "    Engineered automated risk reports for quarterly and daily distribution.\n",
    "    Designed a comprehensive financial analysis dashboard for vendor viability.\n",
    "    Conducted rigorous User Acceptance Testing for the credit API. \n",
    "\n",
    "    Projects\n",
    "    Statistical Arbitrage Trading Strategy\n",
    "    Leveraged public historical market data to identify mean-reverting stock pairs based on\n",
    "    cointegration analysis\n",
    "    Backtesting the strategy over 3 years of data, evaluating performance with a Sharpe ratio (1.4),\n",
    "    max drawdown (-12%), and win rate (60%), demonstrating consistent profitability in diverse\n",
    "    market conditions.\n",
    "\n",
    "    Skills: Python (Pandas, NumPy, Matplotlib, Altair, Spacy, Selenium, Scikit, PyTorch, TensorFlow),\n",
    "    SQL (MySQL, PostgreSQL), Git, Tableau, PowerBI, NLP\n",
    "\"\"\"\n",
    "\n",
    "# jd_content = \"\"\"\n",
    "# About the job\n",
    "# Machine Learning Engineer - Cambridge - Cutting Edge Consultancy\n",
    "\n",
    "\n",
    "\n",
    "# A Machine Learning Engineer is required for a very exciting consultancy. As a Machine Learning Engineer, you will play a key role in making real-world impact and work with an elite teams of some of the top scientists, engineers, and designers in the company.\n",
    "\n",
    "\n",
    "# Machine Learning Engineer - Ideal skillset would include:\n",
    "\n",
    "# Top Academics in a relevant field\n",
    "# Strong knowledge of TensorFlow, PyTorch, Keras and Scikit-Learn\n",
    "# Ideally 1+ year professional experience as a Machine Learning Engineer\n",
    "# Research minded and experimental approach to problem solving\n",
    "\n",
    "\n",
    "# This is a very innovative consultancy in the heart of Cambridge working on some exciting cyber projects.\n",
    "\n",
    "\n",
    "# Machine Learning Engineer - Benefits:\n",
    "\n",
    "# Private medical insurance for you and your family\n",
    "# A comprehensive relocation package\n",
    "# Working within an exceptional team\n",
    "# 25 Days annual holiday + bank holidays\n",
    "# In office perks such as lunch and snacks provided\n",
    "\n",
    "\n",
    "# Machine Learning Engineer - Cambridge - Cutting Edge Consultancy\n",
    "# \"\"\"\n",
    "\n",
    "jd_content = \"\"\"\n",
    "About the job\n",
    "About the Company: Oeson is a leading IT corporation globally recognized for its expertise in providing top-notch IT and Ed-tech services. Specializing in digital marketing, data science, data analytics, UI-UX design, web development, and app development, we are dedicated to innovation, excellence, and empowering talents worldwide.\n",
    "\n",
    "Learn More: www.oesonlearning.com\n",
    "\n",
    "\n",
    "\n",
    "Job Summary:\n",
    "\n",
    "\n",
    "\n",
    "Oeson is seeking enthusiastic individuals who are looking to learn with us in the field of Data Science while working on live projects internationally. We are not just offering a flexible work environment but also offering to work with people in a global team.\n",
    "\n",
    "\n",
    "\n",
    "Projects You Will Work On:\n",
    "\n",
    "\n",
    "\n",
    "- Finance Fraud Detection: Develop advanced fraud detection algorithms leveraging financial data analysis.\n",
    "\n",
    "- Recommender System: Contribute to personalized recommendation systems, enhancing user experiences across platforms.\n",
    "\n",
    "- Sentiment Analysis: Explore sentiment analysis to extract insights from textual data, shaping user sentiment understanding.\n",
    "\n",
    "- Chatbots: Engage in intelligent chatbot development, revolutionizing customer interactions and support.\n",
    "\n",
    "- Image/Audio Video Classification: Push boundaries with multimedia technology by working on image and audio video classification projects.\n",
    "\n",
    "- Text Analysis: Uncover hidden patterns in textual data through sophisticated text analysis techniques.\n",
    "\n",
    "\n",
    "\n",
    "Roles & Responsibilities:\n",
    "\n",
    "\n",
    "\n",
    "- Collaborate with our esteemed data science experts to collect, clean, and analyze extensive datasets, honing skills in data preprocessing and visualization.\n",
    "\n",
    "- Contribute to the development of predictive models and algorithms, employing cutting-edge machine learning techniques to solve real-world challenges.\n",
    "\n",
    "- Work closely with team members to design, implement, and evaluate experiments, fostering a collaborative and innovative environment.\n",
    "\n",
    "- Stay updated with the latest industry trends and best practices in data science, applying newfound knowledge to enhance project outcomes.\n",
    "\n",
    "\n",
    "\n",
    "Qualifications:\n",
    "\n",
    "\n",
    "\n",
    "- Currently pursuing any degree showcasing a strong commitment to continuous learning and professional growth.\n",
    "\n",
    "- Exceptional written and verbal communication skills, vital for effective collaboration and articulation of complex ideas.\n",
    "\n",
    "- Demonstrated ability to work both independently and as part of a cohesive team, highlighting adaptability and strong teamwork capabilities.\n",
    "\n",
    "\n",
    "\n",
    "Note:\n",
    "\n",
    "\n",
    "\n",
    "This position is unpaid. After submitting your application, our team will contact you to proceed with the application details and joining process.\n",
    "\n",
    "\n",
    "\n",
    "Location: \n",
    "\n",
    "Remote : United States\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6409]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_resume = clean_resume(resume_content)\n",
    "cleaned_jd = clean_text(jd_content)\n",
    "compute_similarity(cleaned_resume, cleaned_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experience risk technology analyst rj ’ brien associate may 2024 aug. 2024 chicago il developed python-based solution automate financial audit request reducing work analyst dynamically generating scheduling 15+ personalized email bi-weekly led project concept deployment including training future maintainer creating power bi dashboard monitoring request manually sending custom email ad hoc identified need developed python gui generating customized anonymous test data user technical expertise served ambassador new ai tool interviewing coworkers identify pain point ai adoption conducting 10+ one-on-one demo teaching leverage gen. ai data science intern cloudquant may 2023 aug. 2023 chicago il expanded data catalog 8000+ datasets seamless integration various data apis dynamic web scraper strategically utilized new openai api automate data entry cleaning process significantly enhancing efficiency reducing manual workload drove insight analysis data visualization summer intern rj ’ brien associate may 2022 aug. 2022 chicago il engineered automated risk report quarterly daily distribution designed comprehensive financial analysis dashboard vendor viability conducted rigorous user acceptance testing credit apitableau altair spacy python panda nlp git postgresql selenium numpy powerbi tensorflow pytorch scikit matplotlib sql mysql'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p j g ( )\n",
      "https://github.com/jacksongiemza boulder, co\n",
      "\n",
      "enthusiastic information science student with hands-on experience as a data scientist,\n",
      "equipped with technical and analytical skills to derive data-driven decisions. passionate\n",
      "about harnessing data to solve complex meaningful problems in a vibrant, innovative setting.\n",
      "\n",
      "education\n",
      "university of colorado, boulder, co | expected graduation may 2025 bachelor of science, information science | minor: philosophy\n",
      "relevant courses:                               applications & programs:\n",
      "data visualization, statistics, python for info sci 1&2       python (pandas, numpy, matplotlib, altair), excel,\n",
      "r for data science, logic, quantitative reason.            openai api, selenium, git, r, sql, excel, tableau,\n",
      "tkinter, power platforms.\n",
      "\n",
      "experience\n",
      "risk technology analyst | rj o’brien associates        may 2024 - aug. 2024, chicago, il\n",
      "i was invited to return to rjo’s risk team following my internship with them in 2022. drawing on the\n",
      "skills i developed through prior internships and academic work, i successfully led key projects from\n",
      "concept to completion and contributed to several other high-impact initiatives.\n",
      "developed a python-based solution to automate financial audit requests, reducing work for\n",
      "credit analysts by dynamically generating and scheduling personalized emails.\n",
      "led the project from concept to deployment, including training future maintainers and creating\n",
      "a power bi dashboard for monitoring requests and manually sending emails ad hoc.\n",
      "identified the need for and developed a python gui for generating customized anonymous test\n",
      "data for users of all technical expertise.\n",
      "served as an ambassador for new ai tools by interviewing coworkers to identify pain points in\n",
      "ai adoption and conducting demos to facilitate user adoption and streamline workflows.\n",
      "\n",
      "data science intern | cloudquant may 2023 - aug. 2023, chicago, il\n",
      "over my productive summer at cloudquant, i successfully executed 4 major projects\n",
      "and efficiently managed numerous smaller tasks, with strong commitment to driving\n",
      "significant results.\n",
      "expanded the data catalog by 8000+ datasets through seamless integration\n",
      "of various data apis.\n",
      "developed dynamic web scrapers using selenium for building datasets.\n",
      "strategically utilized the new openai api to automate data entry and cleaning\n",
      "processes, significantly enhancing efficiency while reducing manual workload.\n",
      "drove insights through analysis and data visualization\n",
      "\n",
      "summer intern | rj o’brien associates                may 2022 - aug. 2022, chicago, il\n",
      "throughout my summer at rjo, the oldest and largest independent futures brokerage\n",
      "firm in the us, i worked on various projects and tasks for the credit and risk teams.\n",
      "engineered automated risk reports for quarterly and daily distribution.\n",
      "streamlined customer financial information retrieval by designing a centralized interface with\n",
      "microsoft powerapps for the credit team.\n",
      "designed a comprehensive financial analysis dashboard for evaluating vendor viability\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_markdown(text):\n",
    "    \"\"\"Removes advanced Markdown syntax while preserving readable text.\"\"\"\n",
    "    \n",
    "    # Remove headers (e.g., ###, ##, #)\n",
    "    text = re.sub(r'#{1,6}\\s*', '', text)  \n",
    "\n",
    "    # Remove bold (**text**) and italic (*text* or _text_)\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)  # Bold\n",
    "    text = re.sub(r'\\*(.*?)\\*', r'\\1', text)      # Italic\n",
    "    text = re.sub(r'_(.*?)_', r'\\1', text)        # Italic with underscore\n",
    "    \n",
    "    # Remove inline code (`code`)\n",
    "    text = re.sub(r'`(.*?)`', r'\\1', text)\n",
    "\n",
    "    # Remove links but keep the anchor text: [text](url)\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', text)\n",
    "\n",
    "    # Remove horizontal rules (---, ***, ___)\n",
    "    text = re.sub(r'(\\n[-*_]{3,}\\n)', '\\n', text)\n",
    "\n",
    "    # Remove list markers (-, *, +) and extra spaces\n",
    "    text = re.sub(r'^\\s*[-*+] ', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove extra spaces caused by formatting\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text).strip()\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "resume_cleaned = clean_markdown(resume)\n",
    "\n",
    "print(resume_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['data-driven decisions', 'derive data-driven', 'data', 'science', 'information science', 'science student', 'enthusiastic information', 'data science', 'data scientist', 'hands-on experience', 'analytical skills', 'information', 'developed', 'boulder', 'risk', 'aug', 'chicago', 'projects', 'python', 'excel', 'scientist', 'equipped', 'decisions', 'data visualization', 'summer', 'credit', 'enthusiastic', 'student', 'hands-on', 'analytical', 'derive', 'data-driven', 'financial', 'experience', 'o’brien associates', 'science intern', 'openai api', 'innovative setting', 'skills', 'concept', 'technical', 'solve complex', 'complex meaningful', 'meaningful problems', 'api', 'financial information', 'power', 'o’brien', 'associates', 'harnessing data', 'team', 'work', 'visualization', 'openai', 'successfully', 'experience risk', 'led', 'intern', 'requests', 'emails', 'generating', 'automate', 'selenium', 'adoption', 'dashboard', 'rjo', 'reducing', 'cloudquant', 'datasets', 'tasks', 'analysis', 'data apis', 'information retrieval', 'quantitative reason', 'automate data', 'risk team', 'risk teams', 'education university', 'expected graduation', 'philosophy relevant', 'info sci', 'passionate', 'vibrant', 'innovative', 'setting', 'credit analysts', 'harnessing', 'solve', 'complex', 'meaningful', 'problems', 'power platforms', 'credit team', 'visualization summer', 'summer intern', 'key projects', 'project', 'risk technology', 'successfully led', 'minor', 'applications', 'programs', 'statistics', 'pandas', 'numpy', 'matplotlib', 'altair', 'logic', 'test data', 'major projects', 'education', 'colorado', 'expected', 'bachelor', 'philosophy', 'sci', 'quantitative', 'reason', 'data catalog', 'reducing work', 'data entry', 'automate financial', 'technology analyst', 'git', 'sql', 'tableau', 'tkinter', 'apis', 'developed dynamic', 'user adoption', 'analyst', 'internship', 'internships', 'analysts', 'university', 'graduation', 'relevant', 'info', 'python gui', 'teams', 'technical expertise', 'platforms', 'prior internships', 'users', 'user', 'automated risk', 'risk reports', 'future', 'futures', 'academic work', 'financial analysis', 'led key', 'technology', 'analysis dashboard', 'drawing', 'initiatives', 'invited', 'return', 'audit requests', 'personalized emails', 'successfully executed', 'deployment', 'including', 'hoc', 'prior', 'academic', 'key', 'completion', 'contributed', 'high-impact', 'dynamically generating', 'identified', 'expertise', 'monitoring requests', 'sending emails', 'python-based', 'solution', 'audit', 'dynamically', 'scheduling', 'personalized', 'productive summer', 'served', 'workflows', 'financial audit', 'training', 'maintainers', 'creating', 'monitoring', 'manually', 'sending', 'executed', 'major', 'results', 'expanded', 'gui', 'customized', 'anonymous', 'test', 'generating customized']\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/LIAAD/yake\n",
    "\n",
    "import yake\n",
    "\n",
    "def yake_extract_keywords(text, num_keywords=10):\n",
    "    \"\"\"Extracts top keywords using YAKE.\"\"\"\n",
    "    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=2, dedupLim=1, top=200)\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    return [kw[0] for kw in keywords]  # Return only the keyword text\n",
    "\n",
    "\n",
    "keywords = yake_extract_keywords(resume_cleaned)\n",
    "\n",
    "print(len(keywords))\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "['developed dynamic web scrapers using selenium', 'largest independent futures brokerage firm', 'expected graduation may 2025 bachelor', 'manually sending emails ad hoc', 'streamlined customer financial information retrieval', 'successfully executed 4 major projects', 'efficiently managed numerous smaller tasks', '’ brien associates may 2024', 'generating customized anonymous test data', '’ brien associates may 2022', 'co enthusiastic information science student', 'solve complex meaningful problems', 'including training future maintainers', 'engineered automated risk reports', 'automate financial audit requests', 'successfully led key projects', 'comprehensive financial analysis dashboard', 'experience risk technology analyst', 'data visualization summer intern', 'scheduling personalized emails', 'automate data entry', 'significantly enhancing efficiency', 'power bi dashboard', 'philosophy relevant courses', 'p j g', 'info sci 1', 'identify pain points', 'https :// github', 'evaluating vendor viability', 'driving significant results', 'data science intern', 'risk team following', 'reducing manual workload', 'new ai tools', 'facilitate user adoption', 'cloudquant may 2023', 'various data apis', 'new openai api', 'altair ), excel', 'information science', 'various projects', 'data visualization', 'rjo ’', 'dynamically generating', 'data science', 'risk teams', 'openai api', 'monitoring requests', 'ai adoption', 'harnessing data', 'derive data', 'data scientist', 'data catalog', 'reducing work', 'power platforms', 'productive summer', 'credit team', 'strong commitment', 'streamline workflows', 'strategically utilized', 'seamless integration', 'quantitative reason', 'prior internships', 'microsoft powerapps', 'interviewing coworkers', 'innovative setting', 'impact initiatives', 'education university', 'drove insights', 'driven decisions', 'daily distribution', 'conducting demos', 'cleaning processes', 'centralized interface', 'based solution', 'academic work', 'credit analysts', 'technical expertise', 'selenium', 'python gui', 'jacksongiemza boulder', 'building datasets', 'analytical skills', '2 python', 'il throughout', 'tasks', 'co', '2024', 'science', 'led', 'experience', 'analysis', 'summer', '2022', '2022', 'developed', 'developed', 'developed', 'excel', 'cloudquant', '2023', 'credit', 'technical', 'skills', 'rjo', 'python', 'python', 'datasets', 'boulder', 'il', 'il', 'worked', 'vibrant', 'users', 'us', 'tkinter', 'tableau', 'statistics', 'sql', 'several', 'served', 'rj', 'rj', 'return', 'r', 'r', 'quarterly', 'project', 'programs', 'passionate', 'pandas', 'oldest', 'numpy', 'need', 'minor', 'matplotlib', 'logic', 'invited', 'internship', 'identified', 'high', 'hands', 'git', 'expanded', 'equipped', 'drawing', 'designing', 'designed', 'deployment', 'creating', 'contributed', 'concept', 'concept', 'completion', 'com', 'colorado', 'chicago', 'chicago', 'chicago', 'aug', 'aug', 'aug', 'applications', 'ambassador', '8000']\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.org/project/rake-nltk/\n",
    "\n",
    "from rake_nltk import Rake\n",
    "\n",
    "def nltk_rake(text):\n",
    "    rake_nltk_var = Rake()\n",
    "\n",
    "    rake_nltk_var.extract_keywords_from_text(text)\n",
    "    keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "\n",
    "    return keyword_extracted\n",
    "\n",
    "nltk_keywords = nltk_rake(resume_cleaned)\n",
    "\n",
    "print(len(nltk_keywords))\n",
    "print(nltk_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jacks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
